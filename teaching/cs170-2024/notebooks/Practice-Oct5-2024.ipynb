{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "21ad6d4e",
   "metadata": {},
   "source": [
    "### Problem 1\n",
    "Read the noisy text data from the datafile [typos20.data](https://www.mbolonkin.info/teaching/cs170-2024/notebooks/typos20.data).\n",
    "- Estimate output probabilities\n",
    "- Estimate transition probabilities\n",
    "\n",
    "Use Laplace smoothing.\n",
    "\n",
    "Implement Viterbi algorithm for HMM. Find the most likely original text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d8a20f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c44b2b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "orig, typo = [], []\n",
    "i2c, c2i = {}, {}\n",
    "i = 0\n",
    "with open('typos20.data') as fin:\n",
    "    for line in fin:\n",
    "        toks = line.strip().split(' ')\n",
    "        if len(toks) < 2:\n",
    "            continue\n",
    "        orig.append(toks[0])\n",
    "        typo.append(toks[1])\n",
    "        if toks[0] not in c2i:\n",
    "            c2i[toks[0]] = i\n",
    "            i2c[i] = toks[0]\n",
    "            i += 1\n",
    "        if toks[1] not in c2i:\n",
    "            c2i[toks[1]] = i\n",
    "            i2c[i] = toks[1]\n",
    "            i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "514cfb09",
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = 1e-10\n",
    "n = len(i2c)\n",
    "A = np.zeros((n, n))\n",
    "for t in range(len(orig)-1):\n",
    "    i = c2i[orig[t]]\n",
    "    j = c2i[orig[t+1]]\n",
    "    A[i,j] += 1\n",
    "A = (A + eps)/ (A.sum(axis=1) + n*eps)\n",
    "\n",
    "pi = np.zeros(n)\n",
    "B = np.zeros((n, n))\n",
    "for t in range(len(orig)):\n",
    "    i = c2i[orig[t]]\n",
    "    j = c2i[typo[t]]\n",
    "    B[i,j] += 1\n",
    "    pi[i] += 1\n",
    "B = (B + eps) / (B.sum(axis=1) + n*eps)\n",
    "pi = pi/(pi.sum() + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9ca83ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "T = 10000\n",
    "X = np.zeros((n, T))\n",
    "Y = np.zeros((n, T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2d2adf28",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(n):\n",
    "    X[i,0] = np.log(pi[i]) + np.log(B[i, c2i[typo[0]]])\n",
    "    \n",
    "for t in range(1, T):\n",
    "    for i in range(n):\n",
    "        p = X[0, t-1] + np.log(A[0, i]) +  np.log(B[i, c2i[typo[t]]])\n",
    "        idx = 0\n",
    "        for j in range(1, n):\n",
    "            p_ji = X[j, t-1] + np.log(A[j, i]) +  np.log(B[i, c2i[typo[t]]])\n",
    "            if p_ji > p:\n",
    "                p = p_ji\n",
    "                idx = j\n",
    "        X[i, t] = p\n",
    "        Y[i, t] = idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5a2a60b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "restored = ['a']*T\n",
    "idx = np.argmax(X[:,-1])\n",
    "\n",
    "for t in range(T):\n",
    "    restored[T-t-1] = i2c[idx]\n",
    "    idx = int(Y[idx, T-t-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cf4a2d2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.008743730805770972\n",
      "0.006396235169351097\n"
     ]
    }
   ],
   "source": [
    "err1 = 0\n",
    "for i in range(T):\n",
    "    if orig[i] != typo[i]:\n",
    "        err1 += 1\n",
    "print(err1/len(orig))\n",
    "\n",
    "err2 = 0\n",
    "for i in range(T):\n",
    "    if orig[i] != restored[i]:\n",
    "        err2 += 1\n",
    "print(err2/len(orig))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af327b9b",
   "metadata": {},
   "source": [
    "### Problem 2\n",
    "Solve the above problem but considering bi-grams (pairs of characters) instead of single characters. For example, in the word \"PROBLEM\" we have bigrams {\"PR\", \"RO\", \"BL\", \"LE\", \"EM\"}. Compare the recovery accuracy to the original error."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37c7687a",
   "metadata": {},
   "source": [
    "### Problem 3\n",
    "Use the typo data from the filetry estimate the probabi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a66f3242",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
